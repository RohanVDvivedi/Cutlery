1. Tasks picked

2. Add new datastructure types tasks (*future)

STREAM
 * all sprint_* functions to be updated to serialize_* functions for all Cutlery data-structures, each of which return -1 for failure and 0 forsuccess

ALLOCATOR
 * uc_allocator -> an allocators for microcontrollers
   * struct uc_allocator_context
   {
   		void* memory;
   		cy_uint memory_size;
   		cy_uint block_alignment; // == LCM(_Alignof(any_block), _Alignof(free_block))
   		any_block* first_block; // this may not be same as memory
   		linked_list all_blocks; // contains all the blocks, the position of the block here controls its size
   														// only a block present in all_blocks should be inserted in free_blocks
   														// and a block whose size could change (due to splitting or coalescing) must be removed from the free_blocks, before you do it
   														// all blocks must be present in all_blocks but only free blocks are present in free_blocks
   		bst free_blocks;	// compared by get_block_size
   }
   * struct any_block
   {
   		int is_free:1;
   		int is_marked:1; // -> for mark and sweep GC
   		llnode ab_node;		// intrusive node for all_blocks
   }
   * struct free_block
   {
   		any_block any;		// even a free block is any block
   		bst_node fb_node;	// intrusive node for free_blocks
   }
   * internal api
     * cy_uint get_block_size(any_block* b); // total size of the block
     * any_block* get_next_block(any_block* b);
     * any_block* get_prev_block(any_block* b);
     * any_block* allocate_block(cy_uint size); // returns block with atleast size as block size, and always aligned to uc_allocator_context->block_alignment
       * size = max(size, sizeof(free_block)) // only allocate blocks of size free_block or more
       * disintegrates any block with later part of the block being free
       * find block b that is free and is atleast size in size
       * remove b from free_blocks, reset its is_free bit, marking it allocated
       * get s = size of b
       * if s - size >= sizeof(free_block), then calculate b2 using memory_get_first_aigned_in_region(b + size, s - size, uc_allocator_context->block_alignment)
         * if b2 != NULL and s2 = (b + s - b2), if s2 > sizeof(free_block), then make a new free block at b2, insert it in all_blocks and then in free_blocks
         * for testing print reasons of what fails block split
     * int deallocate_block(any_block* b);
       * mark it free
       * initialize_bstnode(&(((free_block*)b)->fb_node));
       * insert it in free_blocks
       * check if the next_block is free, if free remove both from free_blocks and the next_block from all_blocks, then insert it back in free_blocks
     	 * check if the prev block is free, if free remove both from free_blocks and it from the all_blocks, then insert it back in free_blocks
     * usable memory of the block is at position (void*)(((any_block*)b)+1)
   * external api
     * to allocate with alignment requirements A and size requirements S
       * allocate block B of size = sizeof(any_block) + (A-1) + sizeof(void*) + S
       * return pointer p = UINT_ALIGN_UP(((cy_uint)B) + sizeof(any_block) + sizeof(void*), A)
       * and then do memory_move(p - sizeof(void*), &B, sizeof(void*)), to store the pointer to the block that was allocated
 * Make compute-only libraries like HTTPparser, JSONparser, Cutlery (itself), TupleStore and TupleIndexer use cutlery allocator interface
 * reafactor stream_to_read_until_dstring to use cutlery allocators

HEAP tasks (NEW DATASTRUCTURE inclusion)
 * implement a node based intrusive fibonacci heap. (binomial heap will not be supported, strict constraints of binomial heap will give us no benefit)
struct fibheapnode
{
	// must be the first element of this node, so that children and root_list can use the same node_offset as the fibheap.node_offset
	llnode sibling_links;

	// parent of this node, NULL if it exists in the rootlist
	void* parent;

	// number of children
	cy_uint degree;

	// the below bit will be set if the node lost a child since it was merged with its parent, this bit will be cleared as soon as it gets added to rootlist
	int lost_child_marker;

	// linkedlist of its children
	linkedlist children;
};
struct fibheap
{
	heap_info info;

	cy_uint node_offset;

	// pointer to the top of the priority_queue, this node must be present in the root_list
	void* top_node;

	// linkedlist of its roots
	linkedlist root_list;
};
 * initialize_fibheap -> makes a new empty fibheap
 * merge_fibheap -> merge root lists of the other fibheap, update the top_node
 * get_top_of_fibheap -> returns the top element
 * pop_from_fibheap -> removes top element, and adds all its children to the root_list, update the top_node
 * push_to_fibheap -> inserts the element to the rootlist and updates the top_node
 * remove_from_fibheap -> removes node from fibheap and pushes all its children to the root_list, update the top_node
 * heapify_at -> removes node or any of its children from the tree and puts them back into the root_list, if they pass is_reordering_required test, updates top_node
 * internal functions
   * move_node_to_root_list -> does as suggested, and updates top_node, it will also increments the lost_child_marker of its parent, NOP if its parent is NULL
   * find_new_top_node given the linkedlist -> iterates over root_list and finds the new top_node
   * restore_structure -> creates a hashmap <ELEMENTS_AS_LINKED_LIST with same node_offset> degree -> root node, of fixed size = 32, and then keep on merging nodes with same degree and promoting the parent, then remove all of them into the root_list of fibheap, while keeping track of the top_node

BST tasks (NEW DATASTRUCTURE inclusion * future)
 * provide implementation for TREAP, AA_TREE etc in bst
 * add cy_uint subtree_size (==0 if node is not in any bst) giving the number of nodes in sub tree rooted at the given node 
   * to provide functionality to get_index_of_element_in_bst, get_element_at_index_in_bst OR get_element_count in bst and get_subtree_element_count (internal function).
   * changes only required to subtree_size in bst_rotations.* and bst_core.* source files.

3. Competely new datastructure tasks (*future)

RADIX_TREE tasks (NEW DATASTRUCTURE)
 * radix tree, skip list, will never be part of part of Cutlery, as these data structures need additional nodes to be allocated for insertions, and if these allcations fails we can do nothing but panic and exit
   * additionally they can be implemented with primitives from Cutlery, hence the decission
 * leftist heap will not be supported due to its insignificance in the industry

RANGE QUERY ON INT/UINT ARRAY DATASTRUCTURE tasks
 * use value_arraylist for below functionality and implement their iterative approaches only
 * access methods must be insert, update, find_range
 * implement segment tree => for min, max, sum, product(multiplication), bitwise-and, bitwise-or, bitwise-xor, lcm and hcf
 * implement fenwick tree => for addition, product(multiplication), bitwise-xor => the functions for which their inverse exists
 * implement sparse table => max, min, lcm, hcf => the functions for which f(a,b,c,d,e) = f(f(a,b,c), f(b,c,d,e))
